{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préambule pour Colab\n",
    "\n",
    "Tout d'abord, sélectionnez l'option GPU de Colab avec *Edit > Notebook settings* et sélectionner GPU comme Hardware accelerator. Installer ensuite deeplib avec la comamnde suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ulaval-damas/glo4030-labs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratoire 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from deeplib.visualization import make_vizualization_autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphe computationnel et backprop\n",
    "Cette section a pour but de vous familiariser avec les notions de graphe computationnel et de backpropagation, plus particulièrement leur implémentation PyTorch. Dans le dernier laboratoire, vous avez vu une version haut-niveau de l'entraînement de réseaux de neurones. À l'inverse, ce laboratoire a pour but de vous donner une intuition du fonctionnement interne de PyTorch. Qui sait? Peut-être voudriez-vous un jour implémenter vous même votre librairie de graphe de calcul?\n",
    "\n",
    "#### Tenseurs et Variables\n",
    "La structure de données de base dans PyTorch est le `Tensor`. Cette structure de données est comparable au `ndarray` numpy. Le package `torch.Tensor` défini des matrices multidimensionnelles et les opérations sur celles-ci. Voici quelques exemples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et initialisation à une normale centrée à 0 et de variance 1.\n",
    "a = torch.Tensor(10,10)\n",
    "print(a) # Initialement, le tenseur contient du 'garbage'. Il peut même contenir des NaN\n",
    "a.normal_()\n",
    "print(a)\n",
    "print(torch.mean(a))\n",
    "print(torch.var(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **REMARQUE** Dans l'exemple précédent, la méthode `normal_()` se termine par un underscore. Cela signifie que cette méthode fait une mutation du `Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.Tensor(10,1).fill_(1)\n",
    "print(b)\n",
    "print(a.matmul(b))\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut facilement transférer un `Tensor` sur GPU. Les opérations sur ces `Tensor` seront exécutées sur GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = a.cuda()\n",
    "b_gpu = b.cuda()\n",
    "print(a_gpu.matmul(b_gpu))\n",
    "print(a_gpu.matmul(b_gpu).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO corrigez cette opération pour multiplier `a` avec `c_gpu` sur cpu\n",
    "c_gpu = a_gpu.matmul(b_gpu)\n",
    "print(a.matmul(c_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis PyTorch 1.0, l'API Variable est discontinué. Nous pouvons simplement spécifier ```requires_grad=True``` au Tensor en question pour activer le calcul des gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En règle générale, les opérations in-place, c'est-à-dire les opérations qui font une mutation directe d'un ```Tensor``` (et qui se terminent par un underscore), ne sont pas disponibles lorsque ```requires_grad``` est égale à ```True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.uniform_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Tensor``` contient quelques attributs intéressant comme les données et le gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a))\n",
    "print(type(a.data))\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons voir dans la prochaine section comment faire la backpropagation du gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient et Backpropagation\n",
    "\n",
    "Grâce au package `torch.autograd`, il est possible d'automatiquement calculer la dérivée de fonctions calculées à partir d'opérations sur les tenseurs. On indique les tenseurs qu'on veut dériver avec `requires_grad=True` (par défaut à False). Dans l'exemple suivant, lors du calcul de `w` (propagation avant), PyTorch construit dynamiquement un graphe de calcul indiquant les liens de dépendance entre les tenseurs et les opérations, ce qui permet la backpropagation.\n",
    "\n",
    "> **NOTE** Contrairement à des librairies comme Tensorflow où le graphe de calcul est statique, PyTorch recrée dynamique le graphe de calcul à chaque itération. Cela permet de modifier la structure du graphe dynamiquement avec du code Python. Par contre, cela rend la visualisation du graphe plus difficile. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "\n",
    "y = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "y.requires_grad = True\n",
    "\n",
    "z = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "z.requires_grad = True\n",
    "\n",
    "f = torch.matmul(x, y) + x + y + z\n",
    "\n",
    "print(x, y, z, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.grad_fn)\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n",
    "print(f.grad)\n",
    "\n",
    "make_vizualization_autograd(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_grad = torch.ones(f.size())\n",
    "f.backward(f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n",
    "print(f.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions\n",
    "- Exécutez deux fois la cellule qui appelle la fonction .backward(). Qu'arrive-t-il? Pourquoi?\n",
    "- Quelles tensors auraient requires_grad=False dans le contexte d'entraînement de réseaux de neurones?\n",
    "- Dans l'exemple précédent, pourquoi `f` n'a-t-il pas de gradient?\n",
    "\n",
    "##### TODO exercice\n",
    "Faites la mise-à-jour des valeurs de y et z et soustrayant $1 \\times 10^{-3}$ fois leur gradient sans créer un nouveau graphe de calcul lors de l'opération. Notez que si le tenseur résultant a un attribut `grad_fn`, un graphe de calcul a été créé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prévenir le calcul de gradient\n",
    "\n",
    "Pour éviter de calculer les gradients pour certains tenseurs, nous utiliserons la méthode `torch.no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "\n",
    "y = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "y.requires_grad = True\n",
    "\n",
    "z = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "z.requires_grad = True\n",
    "\n",
    "f = torch.matmul(x, y) + x + y + z\n",
    "\n",
    "print(f.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    f = torch.matmul(x, y) + x + y + z\n",
    "\n",
    "print(f.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question\n",
    "- Dans quel contexte voudrait-on ne calculer aucun gradient d'un graphe de calcul?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'activation\n",
    "\n",
    "La section suivante a pour but d'explorer les différences entre les fonctions d'activation ReLU et Tanh.\n",
    "\n",
    "#### Question préalable\n",
    "- À quoi sert la fonction d'activation? Sans elle, que devient un réseau multi-couches?\n",
    "\n",
    "#### Visualisation du dataset\n",
    "Pour cette partie, nous utiliserons le dataset des spirales. Vous pouvez voir le code qui a servi à générer le dataset dans la librairie https://github.com/ulaval-damas/glo4030-labs/blob/master/deeplib/datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplib.datasets import SpiralDataset, train_valid_loaders\n",
    "\n",
    "dataset = SpiralDataset()\n",
    "points, labels = dataset.to_numpy()\n",
    "print(points.shape, labels.shape)\n",
    "plt.scatter(points[labels==1,0], points[labels==1,1])\n",
    "plt.scatter(points[labels==0,0], points[labels==0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante,  `train_valid_loaders()` retourne des [DataLoader](http://pytorch.org/docs/0.3.0/data.html#torch.utils.data.DataLoader) pytorch. Il est possible d'itérer sur les données d'un `DataLoader` comme on le ferait sur un liste python.\n",
    "\n",
    "> **PYTHON DEEP DIVE** Pourquoi peut-on itérer facilement sur le `DataLoader`? Parce que la classe implémente la méthode `__iter__`. Ainsi, quand on fait\n",
    "```\n",
    "for x in data_loader:\n",
    "```\n",
    "la fonction `__iter__` est appelée, ce qui crée un itérateur sur le `DataLoader`. Cet itérateur peut charger les données sur demande puis que la méthode `__next__` est appelée à chaque itération. Il est possible de créer explicitement cet itérateur en appelant la fonction built-in `iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = train_valid_loaders(dataset, 8)\n",
    "\n",
    "for i, (data, label) in enumerate(train_loader):\n",
    "    print(data, label)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour tout itérateur python, on peut utiliser `itertools`. Par exemple, ici, on boucle sur les 10 premiers éléments de l'itérateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for data in itertools.islice(iter(train_loader), 10):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de modèles\n",
    "\n",
    "Ici, on crée des classes qui héritent de `torch.nn.Module`. C'est la classe de base de tout réseau dans PyTorch. `Module` comporte par exemple la méthode `named_parameters()` qui permet d'obtenir toutes les variables entraînables du `Module` ainsi que leur nom. Voici un lien vers la documentation complète:\n",
    "http://pytorch.org/docs/stable/nn.html#torch.nn.Module.\n",
    "\n",
    "##### Exercice\n",
    "Écrivez la fonction forward de TanhModel et ReluModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345) # Both Tanh model and ReLU model will have the same random weights\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(n_layers):\n",
    "            layer = nn.Linear(7,7)\n",
    "            layer.weight.data.normal_(0.0, math.sqrt(2 / 7))\n",
    "            layer.bias.data.fill_(0)\n",
    "            self.layers.append(layer)\n",
    "            self.add_module('layer-%d' % i, layer)\n",
    "        self.output_layer = nn.Linear(7,2)\n",
    "\n",
    "        self.nonzero_grad_stats = None\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        raise NotImplementedError('Defined in children classes')\n",
    "       \n",
    "    \n",
    "    def _forward_output_layer(self, x):\n",
    "        out = self.output_layer(x)\n",
    "        out = F.log_softmax(out, dim=0)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def print_weights_grads(self):\n",
    "        self.nonzero_grad_stats = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(\"-----\\nLayer %d\" % i)\n",
    "            print(\"Weight:\\n%sWeight gradient:\\n%s\\n\" % (str(layer.weight.data), \n",
    "                                                         str(layer.weight.grad)))\n",
    "            if layer.weight.grad is not None:\n",
    "                nonzero_grad_indices = torch.nonzero(layer.weight.grad.data)\n",
    "                nonzero_grad = [layer.weight.grad.data[i,j] for (i,j) in nonzero_grad_indices]\n",
    "                nonzero_grad_mean = np.mean(np.abs(nonzero_grad))\n",
    "                self.nonzero_grad_stats.append((len(nonzero_grad), nonzero_grad_mean))\n",
    "                print(\"Number of nonzero gradient: %f\" % len(nonzero_grad))\n",
    "                print(\"Nonzero grad mean: %f\" % nonzero_grad_mean)\n",
    "        \n",
    "\n",
    "        \n",
    "class RandomReluModel(RandomModel):\n",
    "    \n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__(n_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "class RandomTanhModel(RandomModel):\n",
    "    \n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__(n_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model = RandomReluModel(10)\n",
    "tanh_model = RandomTanhModel(10)\n",
    "relu_model.print_weights_grads()\n",
    "tanh_model.print_weights_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in, data_out = next(iter(train_loader))\n",
    "relu_output = relu_model(data_in)\n",
    "tanh_output = tanh_model(data_in)\n",
    "print(data_in)\n",
    "print(\"ReLU model ouput:\\n\", relu_output)\n",
    "print(\"tanh model ouput:\\n\", tanh_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Exercice\n",
    "Vérifiez que le réseau retourne bel et bien des probabilités. Identifiez la ligne de code qui transforme des nombres arbitraires en probabilité. Indice: il y a une erreur volontaire dans le code que vous devez corriger.\n",
    "\n",
    "#### Analyse du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.NLLLoss()\n",
    "relu_loss = loss(relu_output, data_out)\n",
    "tanh_loss = loss(tanh_output, data_out)\n",
    "print(relu_loss, tanh_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_loss.backward()\n",
    "tanh_loss.backward()\n",
    "relu_model.print_weights_grads()\n",
    "tanh_model.print_weights_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique suivant représente la quantité de poids qui ont un gradient nul lors de la backprop en fonction du numéro de la couche. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(relu_model.nonzero_grad_stats)), [x[0] for x in relu_model.nonzero_grad_stats], label='ReLU')\n",
    "plt.plot(np.arange(len(tanh_model.nonzero_grad_stats)), [x[0] for x in tanh_model.nonzero_grad_stats], label='Tanh')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique suivant représente le gradient moyen (sans tenir compte des gradients nuls) en fonction du numéro de couche. La partie du bas est un zoom sur les premières couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(np.arange(len(relu_model.nonzero_grad_stats)), [x[1] / x[0] for x in relu_model.nonzero_grad_stats],label='ReLU')\n",
    "axs[0].plot(np.arange(len(tanh_model.nonzero_grad_stats)), [x[1] / x[0] for x in tanh_model.nonzero_grad_stats],label='Tanh')\n",
    "axs[0].legend()\n",
    "axs[1].plot(np.arange(4), [x[1] / x[0] for x in relu_model.nonzero_grad_stats[:4]])\n",
    "axs[1].plot(np.arange(4), [x[1] / x[0] for x in tanh_model.nonzero_grad_stats[:4]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante compte le nombre de fois que chaque poids a un gradient non-nul en passant plusieurs points dans le réseaux et en incrémentant le compteur à chaque fois que cela arrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.NLLLoss()\n",
    "layer_index = 1\n",
    "heatmap = np.zeros((7,7))\n",
    "n_batch = 0\n",
    "for data_in, data_out in train_loader:\n",
    "    n_batch += 1\n",
    "    relu_model.zero_grad()\n",
    "    output = relu_model(data_in)\n",
    "    output_loss = loss(output, data_out)\n",
    "    output_loss.backward()\n",
    "    nonzero_grad_indices = torch.nonzero(relu_model.layers[layer_index].weight.grad.data)\n",
    "    for (i, j) in nonzero_grad_indices:\n",
    "        heatmap[i,j] += 1\n",
    "print(n_batch)\n",
    "print(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "n_epoch = 1000\n",
    "relu_losses = []\n",
    "tanh_losses = []\n",
    "relu_optimizer = SGD(relu_model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "tanh_optimizer = SGD(tanh_model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"================\\nEpoch %d done.\" % epoch)\n",
    "    relu_epoch_losses = []\n",
    "    tanh_epoch_losses = []\n",
    "    for data_in, data_out in train_loader:\n",
    "        relu_optimizer.zero_grad()\n",
    "        tanh_optimizer.zero_grad()\n",
    "        \n",
    "        relu_loss = loss(relu_model(data_in), data_out)\n",
    "        tanh_loss = loss(tanh_model(data_in), data_out)\n",
    "        relu_epoch_losses.append(float(relu_loss))\n",
    "        tanh_epoch_losses.append(float(tanh_loss))\n",
    "        \n",
    "        relu_loss.backward()\n",
    "        tanh_loss.backward()\n",
    "        relu_optimizer.step()\n",
    "        tanh_optimizer.step()\n",
    "    relu_losses.append(np.mean(np.asarray(relu_epoch_losses)))\n",
    "    tanh_losses.append(np.mean(np.asarray(tanh_epoch_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(relu_losses)), np.asarray(relu_losses),label='ReLU')\n",
    "plt.plot(np.arange(len(tanh_losses)), np.asarray(tanh_losses),label='Tanh')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Observez la distribution du gradient lors de la backprop. Quelles différences y a-t-il entre la backprop à travers ReLU et à travers tanh?\n",
    "- Est-ce que, pour deux entrées différentes, les mêmes poids ont un gradient élevé?\n",
    "- Changez le nombre de couches du réseau. Qu'observez-vous?\n",
    "- Changez la moyenne de la gaussienne des poids lors de l'initilisation. Qu'observez-vous?\n",
    "- Identifiez un problème avec la tanh. Identifiez un problème avec la ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
