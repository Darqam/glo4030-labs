{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratoire 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from deeplib.visualization import make_vizualization_autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphe computationnel et backprop\n",
    "Cette section a pour but de vous familiariser avec les notions de graphe computationnel et de backpropagation, plus particulièrement leur implémentation PyTorch. Dans le dernier laboratoire, vous avez vu une version haut-niveau de l'entraînement de réseaux de neurones. À l'inverse, ce laboratoire a pour but de vous donner une intuition du fonctionnement interne de PyTorch. Qui sait? Peut-être voudrai vous un jour implémenter vous même votre librairie de graphe de calcul.\n",
    "\n",
    "#### Tenseurs et Variables\n",
    "La structure de données de base dans PyTorch est le `Tensor`. Cette structure de données est comparable au `ndarray` numpy. Le package `torch.Tensor` défini des matrices multidimensionnelles et les opérations sur celles-ci. Voici quelques exemples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1477e-04,  3.0859e-41,  9.3887e-44,  1.5975e-43,  3.2650e-43,\n",
      "          1.3593e-43,  1.6255e-43,  1.4714e-43,  1.5554e-43,  1.5414e-43],\n",
      "        [ 4.4842e-44,  1.4153e-43,  1.6255e-43,  4.4842e-44,  1.4714e-43,\n",
      "          1.5414e-43,  1.4714e-43,  1.6255e-43,  1.4714e-43,  1.3593e-43],\n",
      "        [ 1.5134e-43,  1.4714e-43,  1.6115e-43,  1.3593e-43,  1.6255e-43,\n",
      "          1.4714e-43,  1.5554e-43,  1.5414e-43,  4.4842e-44,  3.1389e-43],\n",
      "        [ 4.4842e-44,  1.6395e-43,  1.5414e-43,  1.4153e-43,  4.4842e-44,\n",
      "          1.5414e-43,  1.5554e-43,  1.5975e-43,  1.5274e-43,  1.3593e-43],\n",
      "        [ 1.5134e-43,  1.4153e-43,  4.4842e-44,  1.3873e-43,  1.4153e-43,\n",
      "          1.5414e-43,  1.6255e-43,  1.5975e-43,  3.2650e-43,  1.4153e-43],\n",
      "        [ 4.4842e-44,  3.1389e-43,  4.4842e-44,  6.7262e-44,  4.4842e-44,\n",
      "          1.4153e-43,  1.6255e-43,  4.4842e-44,  1.4013e-43,  1.4153e-43],\n",
      "        [ 4.4842e-44,  1.6535e-43,  1.3593e-43,  1.5975e-43,  1.4714e-43,\n",
      "          1.3593e-43,  1.5414e-43,  1.3873e-43,  1.4153e-43,  4.4842e-44],\n",
      "        [ 6.8664e-44,  6.4460e-44,  1.4013e-44,  1.3593e-43,  4.4842e-44,\n",
      "          8.5479e-44,  4.4842e-44,  1.6255e-43,  1.5554e-43,  1.5975e-43],\n",
      "        [ 1.3873e-43,  1.4574e-43,  6.4460e-44,  1.1771e-43,  1.4153e-43,\n",
      "          1.5414e-43,  1.6115e-43,  1.5554e-43,  1.5975e-43,  5.6052e-44],\n",
      "        [ 6.8664e-44,  6.7262e-44,  6.1657e-44,  6.8664e-44,  6.7262e-44,\n",
      "          5.7453e-44,  8.0564e+18,  3.0859e-41,  1.6836e+19,  3.0859e-41]])\n",
      "tensor([[-0.7960,  0.3774, -0.8984,  0.1929,  0.8083,  2.0825, -0.1646, -1.2096,\n",
      "          1.3248, -0.3426],\n",
      "        [ 0.2241,  3.2622, -0.1419, -1.1070,  0.7393, -0.3129, -0.4866, -0.5345,\n",
      "         -1.0182,  0.0750],\n",
      "        [-1.3754, -0.6875, -0.5257, -0.5118, -0.9184,  0.6913, -0.1297, -1.2284,\n",
      "         -1.6490,  1.5070],\n",
      "        [-1.3692,  0.3762,  0.6209,  0.0948,  0.6489,  0.3025,  0.1357,  0.4057,\n",
      "          0.2284,  0.6108],\n",
      "        [-0.4635, -1.0200,  0.3228,  0.0493, -2.0384,  0.8075,  0.8384,  0.8824,\n",
      "          0.6155,  2.5019],\n",
      "        [-0.5670, -0.1424,  0.1656, -0.0255, -1.3152,  0.9193, -0.8610, -0.1010,\n",
      "          1.8340,  1.2516],\n",
      "        [ 1.2076, -0.9696, -0.3323,  1.8658,  0.3970, -0.6181, -0.5463, -0.5000,\n",
      "         -1.1416, -0.8526],\n",
      "        [ 0.2876,  0.7499, -1.0379, -1.2912, -0.5997, -0.8787,  0.8241,  0.6530,\n",
      "         -0.0515,  0.7656],\n",
      "        [-0.0361,  0.8185, -0.0979,  0.9052,  0.6045, -2.0238, -0.1961, -0.3980,\n",
      "          0.7610, -0.5626],\n",
      "        [-0.7261, -0.2433, -0.1480, -0.8042, -0.5641,  1.1084,  0.4448, -0.5199,\n",
      "          0.1997, -0.1384]])\n",
      "tensor(-0.0073)\n"
     ]
    }
   ],
   "source": [
    "# Création et initialisation à une normale centrée à 0 et de variance 1.\n",
    "a = torch.Tensor(10,10)\n",
    "print(a) # Initialement, le tenseur contient du 'garbage'. Il peut même contenir des NaN\n",
    "a.normal_()\n",
    "print(a)\n",
    "print(torch.mean(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **REMARQUE** Dans l'exemple précédent, la méthode `normal_()` se termine par un underscore. Cela signifie que cette méthode fait une mutation du `Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[ 1.3746],\n",
      "        [ 0.6996],\n",
      "        [-4.8276],\n",
      "        [ 2.0546],\n",
      "        [ 2.4959],\n",
      "        [ 1.1584],\n",
      "        [-1.4900],\n",
      "        [-0.5789],\n",
      "        [-0.2253],\n",
      "        [-1.3909]])\n",
      "tensor([[ 1.3746],\n",
      "        [ 0.6996],\n",
      "        [-4.8276],\n",
      "        [ 2.0546],\n",
      "        [ 2.4959],\n",
      "        [ 1.1584],\n",
      "        [-1.4900],\n",
      "        [-0.5789],\n",
      "        [-0.2253],\n",
      "        [-1.3909]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.Tensor(10,1).fill_(1)\n",
    "print(b)\n",
    "print(a.matmul(b))\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut facilement transférer un `Tensor` sur GPU. Les opérations sur ces `Tensor` seront exécutées sur GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4672],\n",
      "        [-2.6829],\n",
      "        [ 2.5347],\n",
      "        [ 0.1980],\n",
      "        [ 1.4281],\n",
      "        [ 0.5420],\n",
      "        [-5.5045],\n",
      "        [-0.4362],\n",
      "        [ 2.8634],\n",
      "        [-6.1170]], device='cuda:0')\n",
      "tensor([[-3.4672],\n",
      "        [-2.6829],\n",
      "        [ 2.5347],\n",
      "        [ 0.1980],\n",
      "        [ 1.4281],\n",
      "        [ 0.5420],\n",
      "        [-5.5045],\n",
      "        [-0.4362],\n",
      "        [ 2.8634],\n",
      "        [-6.1170]])\n"
     ]
    }
   ],
   "source": [
    "a_gpu = a.cuda()\n",
    "b_gpu = b.cuda()\n",
    "print(a_gpu.matmul(b_gpu))\n",
    "print(a_gpu.matmul(b_gpu).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-268bd6e44b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO corrigez cette opération pour multiplier `a` avec `c_gpu` sur cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mc_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "#TODO corrigez cette opération pour multiplier `a` avec `c_gpu` sur cpu\n",
    "c_gpu = a_gpu.matmul(b_gpu)\n",
    "print(a.matmul(c_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis PyTorch 1.0, l'API Variable est discontinué. Nous pouvons simplement spécifier ```requires_grad=True``` au Tensor en question pour activer le calcul des gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7960,  0.3774, -0.8984,  0.1929,  0.8083,  2.0825, -0.1646, -1.2096,\n",
       "           1.3248, -0.3426],\n",
       "         [ 0.2241,  3.2622, -0.1419, -1.1070,  0.7393, -0.3129, -0.4866, -0.5345,\n",
       "          -1.0182,  0.0750],\n",
       "         [-1.3754, -0.6875, -0.5257, -0.5118, -0.9184,  0.6913, -0.1297, -1.2284,\n",
       "          -1.6490,  1.5070],\n",
       "         [-1.3692,  0.3762,  0.6209,  0.0948,  0.6489,  0.3025,  0.1357,  0.4057,\n",
       "           0.2284,  0.6108],\n",
       "         [-0.4635, -1.0200,  0.3228,  0.0493, -2.0384,  0.8075,  0.8384,  0.8824,\n",
       "           0.6155,  2.5019],\n",
       "         [-0.5670, -0.1424,  0.1656, -0.0255, -1.3152,  0.9193, -0.8610, -0.1010,\n",
       "           1.8340,  1.2516],\n",
       "         [ 1.2076, -0.9696, -0.3323,  1.8658,  0.3970, -0.6181, -0.5463, -0.5000,\n",
       "          -1.1416, -0.8526],\n",
       "         [ 0.2876,  0.7499, -1.0379, -1.2912, -0.5997, -0.8787,  0.8241,  0.6530,\n",
       "          -0.0515,  0.7656],\n",
       "         [-0.0361,  0.8185, -0.0979,  0.9052,  0.6045, -2.0238, -0.1961, -0.3980,\n",
       "           0.7610, -0.5626],\n",
       "         [-0.7261, -0.2433, -0.1480, -0.8042, -0.5641,  1.1084,  0.4448, -0.5199,\n",
       "           0.1997, -0.1384]], requires_grad=True), tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]], requires_grad=True))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En règle générale, les opérations in-place, c'est-à-dire les opérations qui font une mutation directe d'un ```Tensor``` (et qui se terminent par un underscore), ne sont pas disponibles lorsque ```requires_grad``` est égale à ```True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad has been used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2ce3772d40eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad has been used in an in-place operation."
     ]
    }
   ],
   "source": [
    "a.uniform_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Tensor``` contient quelques attributs intéressant comme les données et le gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(type(a))\n",
    "print(type(a.data))\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons voir dans la prochaine section comment faire la backpropagation du gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient et Backpropagation\n",
    "\n",
    "Variable provient du package `torch.autograd`. Comme le nom du package l'indique, il est possible d'automatiquement calculer la dérivée de fonctions calculées à partir d'opérations sur les variables. On indique les Variables qu'on veut dériver avec `requires_grad=True` (par défaut à False). Dans l'exemple suivant, lors du calcul de `w` (propagation avant), PyTorch construit dynamiquement un graphe de calcul indiquant les liens de dépendance entre les variables et les opérations, ce qui permet la backpropagation.\n",
    "\n",
    "> **NOTE** Contrairement à des librairies comme Tensorflow où le graphe de calcul est statique, PyTorch recrée dynamique le graphe de calcul à chaque itération. Cela permet de modifier la structure du graphe dynamiquement avec du code Python. Par contre, cela rend la visualisation du graphe plus difficile. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5859, -0.0982,  0.0089],\n",
      "        [-0.0021, -0.2330,  0.1494],\n",
      "        [ 0.4645, -0.0151, -0.3053]]) tensor([[-0.6605, -0.4884, -0.2380],\n",
      "        [ 0.7619, -0.5407,  0.1615],\n",
      "        [ 0.2172,  0.0072,  0.1218]], requires_grad=True) tensor([[ 0.9510, -0.2446, -0.1744],\n",
      "        [ 0.5467, -0.3480, -0.5049],\n",
      "        [ 0.7979, -0.0692, -0.1334]], requires_grad=True) tensor([[ 0.4166, -1.0643, -0.5577],\n",
      "        [ 1.1628, -0.9936, -0.2129],\n",
      "        [ 1.0949, -0.2980, -0.4671]], grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "\n",
    "y = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "y.requires_grad = True\n",
    "\n",
    "z = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "z.requires_grad = True\n",
    "\n",
    "f = torch.matmul(x, y) + x + y + z\n",
    "\n",
    "print(x, y, z, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThAddBackward object at 0x7f17108eaf98>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"244pt\" height=\"283pt\"\n",
       " viewBox=\"0.00 0.00 243.50 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-279 239.5,-279 239.5,4 -4,4\"/>\n",
       "<!-- 139737038760592 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139737038760592</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"215,-275 96,-275 96,-254 215,-254 215,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"155.5\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThAddBackward</text>\n",
       "</g>\n",
       "<!-- 139737038761488 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139737038761488</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163,-211.5 44,-211.5 44,-190.5 163,-190.5 163,-211.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-197.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThAddBackward</text>\n",
       "</g>\n",
       "<!-- 139737038760592&#45;&gt;139737038761488 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139737038760592&#45;&gt;139737038761488</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M146.6789,-253.7281C139.0129,-244.3667 127.7404,-230.6012 118.6354,-219.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.2345,-217.1322 112.1908,-211.6128 115.8186,-221.5672 121.2345,-217.1322\"/>\n",
       "</g>\n",
       "<!-- 139737038759080 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139737038759080</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"235.5,-218 181.5,-218 181.5,-184 235.5,-184 235.5,-218\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">Var</text>\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (3, 3)</text>\n",
       "</g>\n",
       "<!-- 139737038760592&#45;&gt;139737038759080 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139737038760592&#45;&gt;139737038759080</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M164.4907,-253.7281C170.8589,-246.0983 179.6688,-235.5431 187.7343,-225.8797\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5435,-227.976 194.2643,-218.056 185.1694,-223.4905 190.5435,-227.976\"/>\n",
       "</g>\n",
       "<!-- 139737038759024 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139737038759024</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"119,-148 0,-148 0,-127 119,-127 119,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"59.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThAddBackward</text>\n",
       "</g>\n",
       "<!-- 139737038761488&#45;&gt;139737038759024 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139737038761488&#45;&gt;139737038759024</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M96.036,-190.2281C89.6766,-181.0503 80.384,-167.6394 72.7621,-156.6396\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.4261,-154.339 66.8538,-148.1128 69.6724,-158.3259 75.4261,-154.339\"/>\n",
       "</g>\n",
       "<!-- 139737038759360 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139737038759360</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"130.5,-34 76.5,-34 76.5,0 130.5,0 130.5,-34\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-20.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">Var</text>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (3, 3)</text>\n",
       "</g>\n",
       "<!-- 139737038761488&#45;&gt;139737038759360 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139737038761488&#45;&gt;139737038759360</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M110.3757,-190.146C116.5061,-179.7802 125.0307,-163.4871 128.5,-148 132.0795,-132.0212 128.2529,-86.4992 124.5,-70 122.4804,-61.1212 119.2003,-51.7791 115.8264,-43.4533\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"119.0368,-42.059 111.8926,-34.2352 112.5985,-44.8065 119.0368,-42.059\"/>\n",
       "</g>\n",
       "<!-- 139737038760088 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139737038760088</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"115.5,-91 13.5,-91 13.5,-70 115.5,-70 115.5,-91\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.5\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139737038759024&#45;&gt;139737038760088 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139737038759024&#45;&gt;139737038760088</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M60.4405,-126.7787C61.069,-119.6134 61.9165,-109.9517 62.6746,-101.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"66.1764,-101.4408 63.5638,-91.1732 59.2032,-100.8291 66.1764,-101.4408\"/>\n",
       "</g>\n",
       "<!-- 139737038760088&#45;&gt;139737038759360 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139737038760088&#45;&gt;139737038759360</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M71.1158,-69.7281C75.6612,-62.3272 81.8972,-52.1738 87.684,-42.7517\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"90.7736,-44.4089 93.0247,-34.056 84.8087,-40.7454 90.7736,-44.4089\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f17108eaf28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f.grad_fn)\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n",
    "print(f.grad)\n",
    "\n",
    "make_vizualization_autograd(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_grad = torch.ones(f.size())\n",
    "f.backward(f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[2.0483, 2.0483, 2.0483],\n",
      "        [0.6537, 0.6537, 0.6537],\n",
      "        [0.8531, 0.8531, 0.8531]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n",
    "print(f.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions\n",
    "- Exécutez deux fois la cellule qui appelle la fonction .backward(). Qu'arrive-t-il? Pourquoi?\n",
    "- Quelles tensors auraient requires_grad=False dans le contexte d'entraînement de réseaux de neurones?\n",
    "- Dans l'exemple précédent, pourquoi `f` n'a-t-il pas de gradient?\n",
    "\n",
    "##### TODO exercice\n",
    "Faites la mise-à-jour des valeurs de y et z et soustrayant $1 \\times 10^{-3}$ fois leur gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prévenir le calcul de gradient\n",
    "\n",
    "Pour éviter de caluler les gradients pour certains tensor, nous utiliserons la méthode `torch.no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "\n",
    "y = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "y.requires_grad = True\n",
    "\n",
    "z = torch.Tensor(3, 3).uniform_(-1, 1)\n",
    "z.requires_grad = True\n",
    "\n",
    "f = torch.matmul(x, y) + x + y + z\n",
    "\n",
    "print(f.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    f = torch.matmul(x, y) + x + y + z\n",
    "\n",
    "print(f.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question\n",
    "- Dans quel contexte voudrait-on ne calculer aucun gradient d'un graphe de calcul?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'activation\n",
    "\n",
    "La section suivante a pour but d'explorer les différences entre les fonctions d'activation ReLU et Tanh.\n",
    "\n",
    "#### Question préalable\n",
    "- À quoi sert la fonction d'activation? Sans elle, que devient un réseau multi-couches?\n",
    "\n",
    "#### Visualisation du dataset\n",
    "Pour cette partie, nous utiliserons le dataset des spirales. Vous pouvez voir le code qui a servi à générer le dataset dans la librairie https://github.com/ulaval-damas/glo4030-labs/blob/master/deeplib/datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7) (1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f17108fccf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1710925dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deeplib.datasets import SpiralDataset, train_valid_loaders\n",
    "\n",
    "dataset = SpiralDataset()\n",
    "points, labels = dataset.to_numpy()\n",
    "print(points.shape, labels.shape)\n",
    "plt.scatter(points[labels==1,0], points[labels==1,1])\n",
    "plt.scatter(points[labels==0,0], points[labels==0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante,  `train_valid_loaders()` retourne des [DataLoader](http://pytorch.org/docs/0.3.0/data.html#torch.utils.data.DataLoader) pytorch. Il est possible d'itérer sur les données d'un `DataLoader` comme on le ferait sur un liste python.\n",
    "\n",
    "> **PYTHON DEEP DIVE** Pourquoi peut-on itérer facilement sur le `DataLoader`? Parce que la classe implémente la méthode `__iter__`. Ainsi, quand on fait\n",
    "```\n",
    "for x in data_loader:\n",
    "```\n",
    "la fonction `__iter__` est appelée, ce qui crée un itérateur sur le `DataLoader`. Cet itérateur peut charger les données sur demande puis que la méthode `__next__` est appelée à chaque itération. Il est possible de créer explicitement cet itérateur en appelant la fonction built-in `iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4970e-02, -3.6307e-01,  6.2350e-04,  1.3182e-01,  9.0659e-03,\n",
      "         -2.4967e-02, -3.5515e-01],\n",
      "        [ 8.7564e-01, -4.6407e-01,  7.6674e-01,  2.1537e-01, -4.0636e-01,\n",
      "          7.6795e-01, -4.4760e-01],\n",
      "        [ 3.5959e+00, -1.2986e+00,  1.2930e+01,  1.6862e+00, -4.6694e+00,\n",
      "         -4.3880e-01, -9.6317e-01],\n",
      "        [ 1.5383e+00,  1.1558e+00,  2.3662e+00,  1.3358e+00,  1.7779e+00,\n",
      "          9.9947e-01,  9.1510e-01],\n",
      "        [ 2.1712e+00,  2.0282e+00,  4.7139e+00,  4.1134e+00,  4.4035e+00,\n",
      "          8.2513e-01,  8.9722e-01],\n",
      "        [-1.4557e+00,  2.0862e+00,  2.1191e+00,  4.3524e+00, -3.0370e+00,\n",
      "         -9.9339e-01,  8.7008e-01],\n",
      "        [-1.7634e+00, -4.2397e+00,  3.1097e+00,  1.7975e+01,  7.4764e+00,\n",
      "         -9.8150e-01,  8.9035e-01],\n",
      "        [ 3.1803e+00,  3.3673e+00,  1.0115e+01,  1.1339e+01,  1.0709e+01,\n",
      "         -3.8738e-02, -2.2378e-01]]) tensor([0, 1, 1, 0, 1, 1, 1, 0])\n",
      "tensor([[ 6.8420e-01,  1.2923e+00,  4.6813e-01,  1.6699e+00,  8.8417e-01,\n",
      "          6.3206e-01,  9.6146e-01],\n",
      "        [-1.8991e+00,  1.6842e+00,  3.6064e+00,  2.8365e+00, -3.1984e+00,\n",
      "         -9.4660e-01,  9.9358e-01],\n",
      "        [ 8.5398e-01, -6.3176e-01,  7.2928e-01,  3.9912e-01, -5.3951e-01,\n",
      "          7.5390e-01, -5.9057e-01],\n",
      "        [-1.5028e+00, -1.2932e+00,  2.2584e+00,  1.6723e+00,  1.9434e+00,\n",
      "         -9.9769e-01, -9.6171e-01],\n",
      "        [-1.0356e+00, -1.2206e+00,  1.0725e+00,  1.4899e+00,  1.2641e+00,\n",
      "         -8.6018e-01, -9.3931e-01],\n",
      "        [-1.9375e+00, -2.6181e-02,  3.7538e+00,  6.8544e-04,  5.0724e-02,\n",
      "         -9.3353e-01, -2.6178e-02],\n",
      "        [-1.6775e+00,  3.6152e+00,  2.8141e+00,  1.3070e+01, -6.0646e+00,\n",
      "         -9.9431e-01, -4.5610e-01],\n",
      "        [ 1.1617e+00,  1.3339e+00,  1.3496e+00,  1.7794e+00,  1.5497e+00,\n",
      "          9.1749e-01,  9.7208e-01]]) tensor([0, 1, 1, 1, 1, 1, 0, 0])\n",
      "tensor([[-1.6645,  1.7116,  2.7707,  2.9296, -2.8491, -0.9956,  0.9901],\n",
      "        [-0.6359, -2.8736,  0.4043,  8.2579,  1.8273, -0.5939, -0.2647],\n",
      "        [-0.9646,  2.4393,  0.9305,  5.9504, -2.3530, -0.8218,  0.6459],\n",
      "        [-1.3258, -4.2446,  1.7579, 18.0165,  5.6276, -0.9701,  0.8926],\n",
      "        [-0.2943, -0.1796,  0.0866,  0.0323,  0.0529, -0.2901, -0.1787],\n",
      "        [ 0.9967, -0.7317,  0.9934,  0.5353, -0.7293,  0.8397, -0.6681],\n",
      "        [ 0.2637, -4.3066,  0.0696, 18.5465, -1.1358,  0.2607,  0.9188],\n",
      "        [ 0.8270, -0.0557,  0.6839,  0.0031, -0.0461,  0.7359, -0.0557]]) tensor([1, 0, 1, 1, 0, 1, 1, 1])\n",
      "tensor([[ 3.6077e+00, -1.5093e+00,  1.3016e+01,  2.2779e+00, -5.4450e+00,\n",
      "         -4.4945e-01, -9.9811e-01],\n",
      "        [-2.8841e+00,  2.5908e+00,  8.3180e+00,  6.7120e+00, -7.4720e+00,\n",
      "         -2.5466e-01,  5.2340e-01],\n",
      "        [-5.1043e+00, -4.1627e-01,  2.6054e+01,  1.7328e-01,  2.1248e+00,\n",
      "          9.2416e-01, -4.0435e-01],\n",
      "        [-4.1898e-01, -4.6107e-03,  1.7555e-01,  2.1258e-05,  1.9318e-03,\n",
      "         -4.0683e-01, -4.6106e-03],\n",
      "        [ 4.6452e+00,  1.5324e+00,  2.1578e+01,  2.3482e+00,  7.1182e+00,\n",
      "         -9.9774e-01,  9.9926e-01],\n",
      "        [ 2.8784e+00, -2.4077e+00,  8.2849e+00,  5.7972e+00, -6.9303e+00,\n",
      "          2.6021e-01, -6.6974e-01],\n",
      "        [ 1.8182e+00, -3.3856e+00,  3.3058e+00,  1.1462e+01, -6.1556e+00,\n",
      "          9.6955e-01,  2.4158e-01],\n",
      "        [-8.8590e-02, -3.1276e-02,  7.8482e-03,  9.7819e-04,  2.7707e-03,\n",
      "         -8.8474e-02, -3.1271e-02]]) tensor([1, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([[ 1.7366, -3.9857,  3.0159, 15.8859, -6.9217,  0.9863,  0.7474],\n",
      "        [-1.3251,  2.3538,  1.7558,  5.5403, -3.1189, -0.9700,  0.7088],\n",
      "        [ 4.7872,  1.3756, 22.9176,  1.8922,  6.5852, -0.9972,  0.9810],\n",
      "        [-0.3396, -0.0318,  0.1153,  0.0010,  0.0108, -0.3331, -0.0318],\n",
      "        [ 1.3208,  2.6539,  1.7445,  7.0429,  3.5052,  0.9689,  0.4686],\n",
      "        [ 1.5726,  1.0369,  2.4729,  1.0751,  1.6306,  1.0000,  0.8608],\n",
      "        [ 2.8319,  1.5942,  8.0199,  2.5415,  4.5147,  0.3047,  0.9997],\n",
      "        [ 0.1904,  0.2244,  0.0363,  0.0504,  0.0427,  0.1893,  0.2225]]) tensor([1, 1, 0, 0, 1, 0, 1, 1])\n",
      "tensor([[ 0.8379, -0.3437,  0.7022,  0.1181, -0.2880,  0.7433, -0.3370],\n",
      "        [ 0.3645, -1.2664,  0.1329,  1.6039, -0.4616,  0.3565, -0.9540],\n",
      "        [ 2.0862, -1.1912,  4.3521,  1.4190, -2.4850,  0.8701, -0.9288],\n",
      "        [ 0.2550, -1.4677,  0.0650,  2.1542, -0.3743,  0.2523, -0.9947],\n",
      "        [ 1.4012,  2.7548,  1.9635,  7.5887,  3.8601,  0.9857,  0.3773],\n",
      "        [-0.0541, -1.3692,  0.0029,  1.8746,  0.0741, -0.0541, -0.9797],\n",
      "        [-1.6876, -1.0163,  2.8479,  1.0329,  1.7151, -0.9932, -0.8502],\n",
      "        [-0.0907,  0.0946,  0.0082,  0.0089, -0.0086, -0.0906,  0.0944]]) tensor([1, 1, 0, 1, 1, 1, 1, 1])\n",
      "tensor([[-1.2951,  2.1824,  1.6772,  4.7630, -2.8264, -0.9622,  0.8187],\n",
      "        [ 0.0400,  0.1753,  0.0016,  0.0307,  0.0070,  0.0400,  0.1745],\n",
      "        [ 0.9331,  1.4606,  0.8707,  2.1332,  1.3629,  0.8035,  0.9939],\n",
      "        [ 0.9408, -2.4038,  0.8852,  5.7781, -2.2616,  0.8081, -0.6727],\n",
      "        [ 1.3579,  4.3600,  1.8440, 19.0096,  5.9206,  0.9774, -0.9386],\n",
      "        [-1.8576, -2.2684,  3.4508,  5.1455,  4.2138, -0.9591, -0.7664],\n",
      "        [ 0.1827,  0.3263,  0.0334,  0.1065,  0.0596,  0.1817,  0.3205],\n",
      "        [-3.5819,  1.0824, 12.8297,  1.1715, -3.8769,  0.4262,  0.8831]]) tensor([1, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([[-3.2753e+00,  2.2122e+00,  1.0727e+01,  4.8937e+00, -7.2455e+00,\n",
      "          1.3327e-01,  8.0127e-01],\n",
      "        [-1.6744e-01, -3.0272e+00,  2.8036e-02,  9.1642e+00,  5.0688e-01,\n",
      "         -1.6666e-01, -1.1410e-01],\n",
      "        [ 8.6189e-01, -2.4788e+00,  7.4285e-01,  6.1444e+00, -2.1364e+00,\n",
      "          7.5907e-01, -6.1533e-01],\n",
      "        [-2.3911e+00, -3.7386e+00,  5.7174e+00,  1.3977e+01,  8.9394e+00,\n",
      "         -6.8199e-01,  5.6216e-01],\n",
      "        [ 4.1451e-01,  1.4846e+00,  1.7182e-01,  2.2041e+00,  6.1539e-01,\n",
      "          4.0274e-01,  9.9629e-01],\n",
      "        [-1.3886e-02, -2.9623e+00,  1.9283e-04,  8.7750e+00,  4.1135e-02,\n",
      "         -1.3886e-02, -1.7838e-01],\n",
      "        [ 2.9289e+00,  1.2697e+00,  8.5787e+00,  1.6121e+00,  3.7188e+00,\n",
      "          2.1106e-01,  9.5500e-01],\n",
      "        [ 2.3259e+00,  1.7459e-01,  5.4100e+00,  3.0482e-02,  4.0609e-01,\n",
      "          7.2818e-01,  1.7371e-01]]) tensor([0, 0, 0, 1, 0, 0, 1, 0])\n",
      "tensor([[ 3.6251,  3.0295, 13.1412,  9.1777, 10.9821, -0.4649,  0.1119],\n",
      "        [-1.9080,  1.5555,  3.6405,  2.4195, -2.9678, -0.9437,  0.9999],\n",
      "        [-0.6422,  0.3432,  0.4124,  0.1178, -0.2204, -0.5989,  0.3365],\n",
      "        [ 1.2251, -2.3927,  1.5010,  5.7248, -2.9314,  0.9409, -0.6809],\n",
      "        [-1.9806, -2.6141,  3.9229,  6.8334,  5.1775, -0.9172, -0.5034],\n",
      "        [ 0.4265, -1.2452,  0.1819,  1.5505, -0.5311,  0.4137, -0.9475],\n",
      "        [ 0.0948, -1.4278,  0.0090,  2.0386, -0.1354,  0.0947, -0.9898],\n",
      "        [-1.7897,  1.9631,  3.2029,  3.8537, -3.5133, -0.9761,  0.9240]]) tensor([0, 1, 0, 0, 0, 1, 1, 1])\n",
      "tensor([[ 1.8596, -1.3070,  3.4581,  1.7082, -2.4305,  0.9586, -0.9654],\n",
      "        [-0.7450,  0.0400,  0.5551,  0.0016, -0.0298, -0.6780,  0.0400],\n",
      "        [ 0.9698,  2.7210,  0.9405,  7.4037,  2.6388,  0.8248,  0.4083],\n",
      "        [-3.1673, -3.1529, 10.0315,  9.9407,  9.9860,  0.0257,  0.0113],\n",
      "        [-0.8363, -1.3035,  0.6994,  1.6990,  1.0900, -0.7422, -0.9645],\n",
      "        [-3.3033, -3.1445, 10.9119,  9.8877, 10.3872,  0.1610,  0.0029],\n",
      "        [-1.9496, -2.6880,  3.8008,  7.2252,  5.2404, -0.9291, -0.4382],\n",
      "        [ 2.8903, -2.4756,  8.3541,  6.1287, -7.1554,  0.2486, -0.6178]]) tensor([0, 0, 1, 1, 1, 1, 0, 1])\n",
      "tensor([[-2.2275, -0.3850,  4.9618,  0.1482,  0.8576, -0.7920, -0.3755],\n",
      "        [-0.5849,  0.8886,  0.3421,  0.7896, -0.5197, -0.5521,  0.7762],\n",
      "        [ 2.5010,  2.2720,  6.2551,  5.1622,  5.6824,  0.5977,  0.7640],\n",
      "        [ 2.2576, -0.0392,  5.0968,  0.0015, -0.0886,  0.7733, -0.0392],\n",
      "        [-0.3084, -0.0448,  0.0951,  0.0020,  0.0138, -0.3035, -0.0448],\n",
      "        [ 1.3491, -2.3188,  1.8201,  5.3770, -3.1284,  0.9755, -0.7330],\n",
      "        [-0.9882, -4.1090,  0.9765, 16.8835,  4.0605, -0.8350,  0.8234],\n",
      "        [ 0.6012,  1.3178,  0.3614,  1.7365,  0.7922,  0.5656,  0.9682]]) tensor([1, 0, 1, 0, 0, 0, 1, 0])\n",
      "tensor([[-0.2435, -0.2388,  0.0593,  0.0570,  0.0581, -0.2411, -0.2365],\n",
      "        [ 0.0578,  0.0709,  0.0033,  0.0050,  0.0041,  0.0578,  0.0708],\n",
      "        [-2.0164,  0.1619,  4.0661,  0.0262, -0.3264, -0.9023,  0.1612],\n",
      "        [ 3.8128,  2.9025, 14.5372,  8.4243, 11.0664, -0.6219,  0.2369],\n",
      "        [-4.6031, -1.7521, 21.1887,  3.0699,  8.0652,  0.9940, -0.9836],\n",
      "        [ 1.0938, -4.0456,  1.1964, 16.3665, -4.4251,  0.8884,  0.7858],\n",
      "        [ 2.1332, -1.0980,  4.5504,  1.2056, -2.3422,  0.8460, -0.8903],\n",
      "        [-2.0938, -0.2814,  4.3840,  0.0792,  0.5893, -0.8663, -0.2777]]) tensor([0, 1, 1, 0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = train_valid_loaders(dataset, 8)\n",
    "\n",
    "for i, (data, label) in enumerate(train_loader):\n",
    "    print(data, label)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour tout itérateur python, on peut utiliser `itertools`. Par exemple, ici, on boucle sur les 10 premiers éléments de l'itérateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.6936,  1.1147,  0.4810,  1.2426, -0.7731, -0.6393,  0.8978],\n",
      "        [-0.6085,  1.0670,  0.3703,  1.1384, -0.6493, -0.5717,  0.8757],\n",
      "        [ 0.9441, -0.1497,  0.8914,  0.0224, -0.1414,  0.8100, -0.1492],\n",
      "        [-0.3746,  1.3828,  0.1404,  1.9121, -0.5180, -0.3659,  0.9824],\n",
      "        [-0.4969, -0.0643,  0.2469,  0.0041,  0.0320, -0.4767, -0.0643],\n",
      "        [-1.4027, -4.1621,  1.9676, 17.3228,  5.8381, -0.9859,  0.8524],\n",
      "        [ 0.7419,  1.6055,  0.5504,  2.5776,  1.1911,  0.6757,  0.9994],\n",
      "        [-4.8770, -1.1485, 23.7848,  1.3190,  5.6012,  0.9865, -0.9121]]), tensor([0, 0, 1, 0, 0, 1, 0, 1])]\n",
      "[tensor([[ 0.9331,  1.4606,  0.8707,  2.1332,  1.3629,  0.8035,  0.9939],\n",
      "        [ 2.9050,  3.8275,  8.4387, 14.6498, 11.1187,  0.2344, -0.6334],\n",
      "        [-3.6120, -3.0842, 13.0464,  9.5125, 11.1402,  0.4532, -0.0573],\n",
      "        [ 0.8852, -0.1474,  0.7836,  0.0217, -0.1305,  0.7741, -0.1469],\n",
      "        [ 0.5414, -1.1150,  0.2931,  1.2432, -0.6036,  0.5153, -0.8979],\n",
      "        [-0.1167,  0.1104,  0.0136,  0.0122, -0.0129, -0.1164,  0.1101],\n",
      "        [ 2.6798,  2.0084,  7.1815,  4.0337,  5.3822,  0.4455,  0.9058],\n",
      "        [-1.9112, -0.5602,  3.6527,  0.3138,  1.0707, -0.9426, -0.5314]]), tensor([0, 0, 1, 1, 1, 1, 1, 1])]\n",
      "[tensor([[ 0.7302,  3.0685,  0.5331,  9.4155,  2.2405,  0.6670,  0.0731],\n",
      "        [ 2.9833, -2.3211,  8.9002,  5.3877, -6.9247,  0.1576, -0.7315],\n",
      "        [-1.2016,  2.4052,  1.4438,  5.7849, -2.8901, -0.9326,  0.6716],\n",
      "        [ 0.8540, -0.6318,  0.7293,  0.3991, -0.5395,  0.7539, -0.5906],\n",
      "        [ 1.2714, -3.8610,  1.6164, 14.9076, -4.9088,  0.9555,  0.6590],\n",
      "        [ 1.5726,  1.0369,  2.4729,  1.0751,  1.6306,  1.0000,  0.8608],\n",
      "        [-2.3911, -3.7386,  5.7174, 13.9770,  8.9394, -0.6820,  0.5622],\n",
      "        [ 0.3690,  0.1001,  0.1361,  0.0100,  0.0369,  0.3606,  0.1000]]), tensor([1, 1, 1, 1, 1, 0, 1, 1])]\n",
      "[tensor([[-2.8297e-02, -3.6322e-02,  8.0073e-04,  1.3193e-03,  1.0278e-03,\n",
      "         -2.8293e-02, -3.6314e-02],\n",
      "        [ 3.7927e-01, -1.3222e+00,  1.4384e-01,  1.7482e+00, -5.0146e-01,\n",
      "          3.7024e-01, -9.6925e-01],\n",
      "        [-1.7897e+00,  1.9631e+00,  3.2029e+00,  3.8537e+00, -3.5133e+00,\n",
      "         -9.7614e-01,  9.2404e-01],\n",
      "        [ 2.8464e+00,  1.6173e+00,  8.1022e+00,  2.6156e+00,  4.6035e+00,\n",
      "          2.9089e-01,  9.9892e-01],\n",
      "        [-2.0019e-01, -2.6528e-03,  4.0077e-02,  7.0371e-06,  5.3106e-04,\n",
      "         -1.9886e-01, -2.6528e-03],\n",
      "        [-3.3070e+00,  1.3462e+00,  1.0937e+01,  1.8123e+00, -4.4520e+00,\n",
      "          1.6470e-01,  9.7489e-01],\n",
      "        [-2.6109e-01, -1.3346e+00,  6.8170e-02,  1.7813e+00,  3.4847e-01,\n",
      "         -2.5814e-01, -9.7224e-01],\n",
      "        [ 2.1629e+00,  3.9291e-01,  4.6781e+00,  1.5438e-01,  8.4983e-01,\n",
      "          8.2977e-01,  3.8288e-01]]), tensor([0, 1, 1, 1, 0, 0, 1, 0])]\n",
      "[tensor([[ 4.7872,  1.3756, 22.9176,  1.8922,  6.5852, -0.9972,  0.9810],\n",
      "        [ 0.6038,  0.0374,  0.3646,  0.0014,  0.0226,  0.5678,  0.0374],\n",
      "        [-1.2951,  2.1824,  1.6772,  4.7630, -2.8264, -0.9622,  0.8187],\n",
      "        [ 0.5160,  1.4254,  0.2663,  2.0318,  0.7355,  0.4934,  0.9894],\n",
      "        [ 2.0151, -1.2771,  4.0607,  1.6311, -2.5735,  0.9029, -0.9572],\n",
      "        [-0.9326,  2.4007,  0.8698,  5.7636, -2.2390, -0.8032,  0.6749],\n",
      "        [-0.6422,  0.3432,  0.4124,  0.1178, -0.2204, -0.5989,  0.3365],\n",
      "        [-1.0932,  2.5638,  1.1951,  6.5732, -2.8028, -0.8881,  0.5462]]), tensor([0, 1, 1, 0, 0, 1, 0, 1])]\n",
      "[tensor([[-0.7645,  0.5103,  0.5845,  0.2605, -0.3902, -0.6922,  0.4885],\n",
      "        [-1.5865, -4.1460,  2.5170, 17.1896,  6.5777, -0.9999,  0.8439],\n",
      "        [-3.3465, -0.8312, 11.1991,  0.6909,  2.7816,  0.2035, -0.7387],\n",
      "        [-1.6775,  3.6152,  2.8141, 13.0697, -6.0646, -0.9943, -0.4561],\n",
      "        [ 2.3898, -3.3739,  5.7109, 11.3832, -8.0628,  0.6830,  0.2302],\n",
      "        [-2.2435,  0.8071,  5.0334,  0.6515, -1.8108, -0.7821,  0.7223],\n",
      "        [ 4.6452,  1.5324, 21.5776,  2.3482,  7.1182, -0.9977,  0.9993],\n",
      "        [-2.6518,  3.1534,  7.0318,  9.9440, -8.3621, -0.4705, -0.0118]]), tensor([0, 1, 0, 0, 1, 1, 0, 0])]\n",
      "[tensor([[-5.5272e-01, -3.3007e-01,  3.0549e-01,  1.0895e-01,  1.8244e-01,\n",
      "         -5.2500e-01, -3.2411e-01],\n",
      "        [-1.0658e-01,  6.6347e-03,  1.1360e-02,  4.4019e-05, -7.0715e-04,\n",
      "         -1.0638e-01,  6.6346e-03],\n",
      "        [-2.2275e+00, -3.8499e-01,  4.9618e+00,  1.4822e-01,  8.5757e-01,\n",
      "         -7.9201e-01, -3.7555e-01],\n",
      "        [ 2.6451e+00,  2.0893e+00,  6.9964e+00,  4.3651e+00,  5.5263e+00,\n",
      "          4.7638e-01,  8.6857e-01],\n",
      "        [ 4.3059e+00,  1.7598e+00,  1.8541e+01,  3.0968e+00,  7.5774e+00,\n",
      "         -9.1852e-01,  9.8220e-01],\n",
      "        [-1.7206e+00,  1.8725e+00,  2.9604e+00,  3.5061e+00, -3.2217e+00,\n",
      "         -9.8880e-01,  9.5485e-01],\n",
      "        [-7.5714e-01,  4.0687e-02,  5.7325e-01,  1.6554e-03, -3.0806e-02,\n",
      "         -6.8684e-01,  4.0676e-02],\n",
      "        [ 3.7832e+00,  2.9725e+00,  1.4313e+01,  8.8355e+00,  1.1245e+01,\n",
      "         -5.9848e-01,  1.6833e-01]]), tensor([0, 0, 1, 1, 0, 1, 0, 0])]\n",
      "[tensor([[-3.9685e+00, -2.4058e+00,  1.5749e+01,  5.7879e+00,  9.5474e+00,\n",
      "          7.3584e-01, -6.7117e-01],\n",
      "        [ 8.3557e-03, -6.1777e-02,  6.9818e-05,  3.8163e-03, -5.1619e-04,\n",
      "          8.3556e-03, -6.1737e-02],\n",
      "        [ 8.1364e-01, -1.3581e-01,  6.6201e-01,  1.8445e-02, -1.1050e-01,\n",
      "          7.2679e-01, -1.3540e-01],\n",
      "        [ 1.8759e+00,  6.4260e-01,  3.5190e+00,  4.1293e-01,  1.2055e+00,\n",
      "          9.5381e-01,  5.9928e-01],\n",
      "        [ 3.3792e+00, -1.5816e+00,  1.1419e+01,  2.5015e+00, -5.3446e+00,\n",
      "         -2.3535e-01, -9.9994e-01],\n",
      "        [ 2.0742e+00, -5.1492e-01,  4.3024e+00,  2.6514e-01, -1.0681e+00,\n",
      "          8.7593e-01, -4.9246e-01],\n",
      "        [-1.7499e+00, -9.6548e-01,  3.0620e+00,  9.3215e-01,  1.6895e+00,\n",
      "         -9.8401e-01, -8.2232e-01],\n",
      "        [ 5.4711e-01, -2.6435e+00,  2.9933e-01,  6.9883e+00, -1.4463e+00,\n",
      "          5.2022e-01, -4.7772e-01]]), tensor([1, 0, 1, 0, 1, 0, 1, 0])]\n",
      "[tensor([[-4.4756, -1.8144, 20.0309,  3.2919,  8.1203,  0.9721, -0.9705],\n",
      "        [-0.5143, -0.1972,  0.2645,  0.0389,  0.1014, -0.4919, -0.1960],\n",
      "        [-0.6444, -0.0880,  0.4153,  0.0077,  0.0567, -0.6007, -0.0879],\n",
      "        [-0.3107, -0.2520,  0.0965,  0.0635,  0.0783, -0.3057, -0.2494],\n",
      "        [-0.5413, -2.9877,  0.2931,  8.9261,  1.6174, -0.5153, -0.1533],\n",
      "        [-3.0390, -1.2964,  9.2357,  1.6806,  3.9398, -0.1024, -0.9626],\n",
      "        [ 0.9021, -0.2315,  0.8138,  0.0536, -0.2089,  0.7847, -0.2295],\n",
      "        [-2.9601,  2.5503,  8.7624,  6.5038, -7.5491, -0.1805,  0.5575]]), tensor([1, 0, 0, 0, 0, 0, 1, 0])]\n",
      "[tensor([[-2.8841,  2.5908,  8.3180,  6.7120, -7.4720, -0.2547,  0.5234],\n",
      "        [ 0.4265, -1.2452,  0.1819,  1.5505, -0.5311,  0.4137, -0.9475],\n",
      "        [ 3.2622,  0.7034, 10.6421,  0.4948,  2.2948, -0.1203,  0.6468],\n",
      "        [ 1.5895,  2.7020,  2.5266,  7.3008,  4.2949,  0.9998,  0.4256],\n",
      "        [ 1.2417,  1.1458,  1.5418,  1.3128,  1.4227,  0.9463,  0.9110],\n",
      "        [-3.5737, -0.6093, 12.7715,  0.3712,  2.1773,  0.4188, -0.5723],\n",
      "        [ 0.4359,  4.3425,  0.1900, 18.8575,  1.8930,  0.4223, -0.9324],\n",
      "        [ 1.4357, -2.1468,  2.0613,  4.6087, -3.0822,  0.9909, -0.8386]]), tensor([0, 1, 1, 1, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for data in itertools.islice(iter(train_loader), 10):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 3.5426, -0.4617, 12.5497,  0.2132, -1.6356, -0.3903, -0.4455],\n",
      "        [ 2.0263,  0.1703,  4.1058,  0.0290,  0.3452,  0.8980,  0.1695],\n",
      "        [ 1.4401, -2.1702,  2.0739,  4.7096, -3.1253,  0.9915, -0.8257],\n",
      "        [-0.7450,  0.0400,  0.5551,  0.0016, -0.0298, -0.6780,  0.0400],\n",
      "        [ 0.4615, -0.8320,  0.2129,  0.6923, -0.3839,  0.4452, -0.7393],\n",
      "        [-1.9112, -0.5602,  3.6527,  0.3138,  1.0707, -0.9426, -0.5314],\n",
      "        [ 1.5182,  1.0723,  2.3049,  1.1498,  1.6279,  0.9986,  0.8783],\n",
      "        [-3.7136,  0.6644, 13.7907,  0.4415, -2.4674,  0.5413,  0.6166]]), tensor([1, 0, 0, 0, 1, 1, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de modèles\n",
    "\n",
    "Ici, on crée des classes qui héritent de `torch.nn.Module`. C'est la classe de base de tout réseau dans pytorch. `Module` comporte par exemple la méthode `named_parameters()` qui permet d'obtenir toutes les variables entraînables du `Module` ainsi que leur nom. Voici un lien vers la documentation complète:\n",
    "http://pytorch.org/docs/0.3.0/nn.html#torch.nn.Module.\n",
    "\n",
    "##### Exercice\n",
    "Écrivez la fonction forward de TanhModel et ReluModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345) # Both Tanh model and ReLU model will have the same random weights\n",
    "        \n",
    "        self.layers = []\n",
    "        for i in range(n_layers):\n",
    "            layer = nn.Linear(7,7)\n",
    "            layer.weight.data.normal_(0.0, math.sqrt(2 / 7))\n",
    "            layer.bias.data.fill_(0)\n",
    "            self.layers.append(layer)\n",
    "            self.add_module('layer-%d' % i, layer)\n",
    "        self.output_layer = nn.Linear(7,2)\n",
    "\n",
    "        self.nonzero_grad_stats = None\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        raise NotImplementedError('Defined in children classes')\n",
    "       \n",
    "    \n",
    "    def _forward_output_layer(self, x):\n",
    "        out = self.output_layer.forward(x)\n",
    "        out = F.log_softmax(out, dim=0)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def print_weights_grads(self):\n",
    "        self.nonzero_grad_stats = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(\"-----\\nLayer %d\" % i)\n",
    "            print(\"Weight:\\n%sWeight gradient:\\n%s\\n\" % (str(layer.weight.data), \n",
    "                                                         str(layer.weight.grad)))\n",
    "            if layer.weight.grad is not None:\n",
    "                nonzero_grad_indices = torch.nonzero(layer.weight.grad.data)\n",
    "                nonzero_grad = [layer.weight.grad.data[i,j] for (i,j) in nonzero_grad_indices]\n",
    "                nonzero_grad_mean = np.mean(np.abs(nonzero_grad))\n",
    "                self.nonzero_grad_stats.append((len(nonzero_grad), nonzero_grad_mean))\n",
    "                print(\"Number of nonzero gradient: %f\" % len(nonzero_grad))\n",
    "                print(\"Nonzero grad mean: %f\" % nonzero_grad_mean)\n",
    "        \n",
    "\n",
    "        \n",
    "class RandomReluModel(RandomModel):\n",
    "    \n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__(n_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "class RandomTanhModel(RandomModel):\n",
    "    \n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__(n_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Layer 0\n",
      "Weight:\n",
      "tensor([[-0.3526, -0.7481, -0.3664, -0.0214,  0.8256,  0.6263, -0.2033],\n",
      "        [ 0.9266,  0.4668,  0.5364,  0.8169,  0.2559, -0.7068, -0.1350],\n",
      "        [-1.1160, -0.3064, -0.7955,  0.2473,  0.4237,  1.0606, -0.2491],\n",
      "        [ 1.0780, -0.5208,  0.2758,  0.0120, -0.6570,  0.1587,  0.9044],\n",
      "        [ 0.1614,  0.0300, -0.2369,  0.3602, -0.1150,  0.2094, -0.5939],\n",
      "        [ 0.2099,  0.0067, -0.1007,  0.0333, -0.0764, -0.0471, -0.1293],\n",
      "        [-0.4333,  0.5793,  0.1326,  0.7287,  0.5808, -0.0513,  0.4890]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 1\n",
      "Weight:\n",
      "tensor([[ 0.0242,  0.1164,  0.4192, -0.9414,  0.9430,  0.1859,  0.3455],\n",
      "        [ 0.3670,  0.8510,  0.2315, -0.3758,  0.1511,  0.8824,  0.2419],\n",
      "        [ 0.1758,  0.0703, -0.6284, -0.5292, -0.9301, -1.1800,  0.2042],\n",
      "        [ 1.1206, -0.1256, -0.2281,  0.1875,  0.4249,  0.1399, -0.0889],\n",
      "        [ 1.0258,  0.5543,  0.4392, -0.1527, -0.7752, -0.2811, -0.1861],\n",
      "        [-0.1664, -0.2569, -0.3510, -0.9809,  0.5899,  0.3759,  0.2613],\n",
      "        [ 0.1039, -0.3731,  0.3715,  0.7183, -0.5955,  1.2846, -0.1801]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 2\n",
      "Weight:\n",
      "tensor([[-0.4162,  0.1891,  0.7648, -1.0300, -0.4802,  0.8963, -0.0787],\n",
      "        [ 0.8033,  0.0086, -0.1378, -1.0861,  0.2594, -0.0326, -0.1495],\n",
      "        [-0.6189,  0.0706, -0.5154,  0.2598, -0.3139,  0.3462,  0.4909],\n",
      "        [ 0.0601, -0.0514,  0.5020, -0.1947, -0.4282, -0.4144, -0.5119],\n",
      "        [ 0.0232, -0.9141, -0.0374, -0.9443, -1.1303,  0.8244, -0.1847],\n",
      "        [ 0.0332,  0.1180,  0.6638,  0.0265, -0.5620, -0.2894, -0.2921],\n",
      "        [-0.3695, -0.7490,  0.0206, -0.1864,  0.2715, -1.0237,  0.2049]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 3\n",
      "Weight:\n",
      "tensor([[-1.2894, -0.1845,  0.3675, -0.1740, -0.7255,  0.0464, -0.4622],\n",
      "        [-0.3196, -0.4615,  0.3168, -0.3306, -0.2428, -0.6077, -0.1386],\n",
      "        [ 0.1322, -0.2746,  0.1462,  0.7966, -0.2879, -1.0783, -0.1681],\n",
      "        [-0.4179,  0.1179, -0.5597,  0.3938, -0.2722, -0.3999,  0.1940],\n",
      "        [ 0.4050,  0.3665,  0.1499, -0.7817,  0.0746,  0.6312, -0.0933],\n",
      "        [-0.8741,  1.3092, -0.0491, -0.0723, -0.2127, -0.2833, -0.0914],\n",
      "        [-0.4998,  0.0238,  0.6145, -0.0408,  0.1925, -0.5526,  0.5799]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 4\n",
      "Weight:\n",
      "tensor([[ 0.5310, -0.0125, -0.5056,  0.2505, -0.2046, -0.1999, -0.2372],\n",
      "        [-0.1198, -0.3800,  0.2246,  0.4026, -0.5748, -0.2200, -0.0656],\n",
      "        [ 0.0048, -0.0008, -0.2176, -0.1890, -0.2419, -0.5771,  0.1931],\n",
      "        [-1.1060,  0.4704, -0.2433, -0.5874, -0.4257, -0.6259,  0.6032],\n",
      "        [-0.3435, -0.0980, -0.5696,  0.4407, -0.0433,  0.3585,  0.1362],\n",
      "        [-0.1456,  0.3126,  0.2726, -0.9562, -0.8213, -0.3716,  0.5941],\n",
      "        [-0.2149,  0.2231, -0.9932,  0.5629,  0.5268, -0.3696,  0.0874]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 5\n",
      "Weight:\n",
      "tensor([[ 0.1009, -0.3853,  0.0368, -0.4540, -0.4380, -0.0670, -0.4403],\n",
      "        [ 0.6768,  0.2805,  0.6309,  0.2574, -0.1615, -0.1747,  0.4323],\n",
      "        [-0.0931, -0.3302, -0.5611, -0.2625, -0.0595, -0.6052,  0.8249],\n",
      "        [ 1.0519,  0.1276, -0.5369, -0.2052, -0.2009, -0.1320,  1.0420],\n",
      "        [ 0.0492, -0.1396, -0.9988,  0.0414,  0.0459, -0.3264, -1.2869],\n",
      "        [ 0.4954,  0.2798, -0.2022,  0.3336,  0.8133, -0.3201,  0.6685],\n",
      "        [ 0.8906,  0.0892, -0.0038, -0.6008, -0.2570, -0.0816, -0.0066]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 6\n",
      "Weight:\n",
      "tensor([[-1.1746, -0.6904, -0.3287, -0.0416, -0.1733, -0.0232, -0.3226],\n",
      "        [-0.2905, -0.2195,  0.5026,  0.7051, -0.2898,  0.3042, -0.0983],\n",
      "        [-0.1882, -0.3245,  0.6044, -0.5695,  0.1159,  1.5630,  0.4904],\n",
      "        [-0.0054,  0.3512,  0.1458, -0.3826,  0.2590,  0.3912,  0.4872],\n",
      "        [ 0.1353,  0.1531, -0.0453,  0.4262,  0.2620,  0.5757, -0.1258],\n",
      "        [-0.0917,  0.3530,  0.2112, -0.4207, -0.6895,  0.7982,  0.0857],\n",
      "        [-0.1348,  0.2213,  1.0095,  0.2629, -0.3495, -1.2156,  0.3347]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 7\n",
      "Weight:\n",
      "tensor([[ 0.3664,  0.2047,  0.2935,  0.3322, -0.1254,  0.5008, -0.1656],\n",
      "        [ 0.2601, -0.0764,  0.2412, -0.1289,  0.9870,  0.4339,  0.3704],\n",
      "        [-0.6455, -1.0067,  0.5543,  1.5753, -0.3543,  0.0957,  0.8867],\n",
      "        [-0.4591,  0.1147,  0.4374, -0.2511, -0.4890, -0.3047, -0.4266],\n",
      "        [ 0.1397, -0.1651,  0.8518, -0.0484, -0.1188, -0.4442,  0.4956],\n",
      "        [ 1.2087,  0.1735, -0.2892,  0.6131,  0.2068,  0.6849, -0.1398],\n",
      "        [ 0.9705, -0.2561, -0.2429, -0.7749,  0.9491, -0.0212, -0.1737]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 8\n",
      "Weight:\n",
      "tensor([[ 0.6289, -0.0879, -0.8610,  0.3710,  0.1778,  0.9245,  0.1028],\n",
      "        [-0.3965,  0.0653,  1.0435, -0.3616, -0.2773, -0.1538, -0.2562],\n",
      "        [-0.2462, -0.6189,  0.1822, -0.0796,  0.4932,  0.4096,  0.1522],\n",
      "        [-0.2252, -0.3882,  0.5134,  0.2689, -0.3421,  0.4927,  0.0038],\n",
      "        [ 0.0567,  0.2283,  0.3299, -1.0837, -0.3701,  0.2546, -0.0060],\n",
      "        [ 0.0903, -0.1677,  0.6272,  0.1524,  0.1383,  0.2606, -0.1180],\n",
      "        [ 0.0291,  0.2490,  0.5029,  0.3559, -0.2441,  0.1945,  0.1847]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 9\n",
      "Weight:\n",
      "tensor([[-0.0688,  0.4294, -0.7579,  0.3925,  0.4945, -0.2480, -0.1614],\n",
      "        [-0.2724,  0.4229,  0.0573,  0.3386, -0.3870,  1.0552, -0.6156],\n",
      "        [-0.4026, -0.9007, -0.2695, -0.5177, -0.3699, -0.0616, -0.0512],\n",
      "        [ 0.3623,  0.0877,  0.2097, -0.3174, -0.9256,  0.7691, -1.1048],\n",
      "        [-0.0054,  0.3573, -0.2189, -0.2419,  0.2915,  0.2092, -0.4534],\n",
      "        [ 0.6693, -0.4130, -0.0347,  0.3008, -0.7064,  0.1705, -0.6194],\n",
      "        [ 0.0239, -0.5009, -0.0022,  0.4796, -0.0286, -0.2365,  0.8795]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 0\n",
      "Weight:\n",
      "tensor([[-0.3526, -0.7481, -0.3664, -0.0214,  0.8256,  0.6263, -0.2033],\n",
      "        [ 0.9266,  0.4668,  0.5364,  0.8169,  0.2559, -0.7068, -0.1350],\n",
      "        [-1.1160, -0.3064, -0.7955,  0.2473,  0.4237,  1.0606, -0.2491],\n",
      "        [ 1.0780, -0.5208,  0.2758,  0.0120, -0.6570,  0.1587,  0.9044],\n",
      "        [ 0.1614,  0.0300, -0.2369,  0.3602, -0.1150,  0.2094, -0.5939],\n",
      "        [ 0.2099,  0.0067, -0.1007,  0.0333, -0.0764, -0.0471, -0.1293],\n",
      "        [-0.4333,  0.5793,  0.1326,  0.7287,  0.5808, -0.0513,  0.4890]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 1\n",
      "Weight:\n",
      "tensor([[ 0.0242,  0.1164,  0.4192, -0.9414,  0.9430,  0.1859,  0.3455],\n",
      "        [ 0.3670,  0.8510,  0.2315, -0.3758,  0.1511,  0.8824,  0.2419],\n",
      "        [ 0.1758,  0.0703, -0.6284, -0.5292, -0.9301, -1.1800,  0.2042],\n",
      "        [ 1.1206, -0.1256, -0.2281,  0.1875,  0.4249,  0.1399, -0.0889],\n",
      "        [ 1.0258,  0.5543,  0.4392, -0.1527, -0.7752, -0.2811, -0.1861],\n",
      "        [-0.1664, -0.2569, -0.3510, -0.9809,  0.5899,  0.3759,  0.2613],\n",
      "        [ 0.1039, -0.3731,  0.3715,  0.7183, -0.5955,  1.2846, -0.1801]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 2\n",
      "Weight:\n",
      "tensor([[-0.4162,  0.1891,  0.7648, -1.0300, -0.4802,  0.8963, -0.0787],\n",
      "        [ 0.8033,  0.0086, -0.1378, -1.0861,  0.2594, -0.0326, -0.1495],\n",
      "        [-0.6189,  0.0706, -0.5154,  0.2598, -0.3139,  0.3462,  0.4909],\n",
      "        [ 0.0601, -0.0514,  0.5020, -0.1947, -0.4282, -0.4144, -0.5119],\n",
      "        [ 0.0232, -0.9141, -0.0374, -0.9443, -1.1303,  0.8244, -0.1847],\n",
      "        [ 0.0332,  0.1180,  0.6638,  0.0265, -0.5620, -0.2894, -0.2921],\n",
      "        [-0.3695, -0.7490,  0.0206, -0.1864,  0.2715, -1.0237,  0.2049]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 3\n",
      "Weight:\n",
      "tensor([[-1.2894, -0.1845,  0.3675, -0.1740, -0.7255,  0.0464, -0.4622],\n",
      "        [-0.3196, -0.4615,  0.3168, -0.3306, -0.2428, -0.6077, -0.1386],\n",
      "        [ 0.1322, -0.2746,  0.1462,  0.7966, -0.2879, -1.0783, -0.1681],\n",
      "        [-0.4179,  0.1179, -0.5597,  0.3938, -0.2722, -0.3999,  0.1940],\n",
      "        [ 0.4050,  0.3665,  0.1499, -0.7817,  0.0746,  0.6312, -0.0933],\n",
      "        [-0.8741,  1.3092, -0.0491, -0.0723, -0.2127, -0.2833, -0.0914],\n",
      "        [-0.4998,  0.0238,  0.6145, -0.0408,  0.1925, -0.5526,  0.5799]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 4\n",
      "Weight:\n",
      "tensor([[ 0.5310, -0.0125, -0.5056,  0.2505, -0.2046, -0.1999, -0.2372],\n",
      "        [-0.1198, -0.3800,  0.2246,  0.4026, -0.5748, -0.2200, -0.0656],\n",
      "        [ 0.0048, -0.0008, -0.2176, -0.1890, -0.2419, -0.5771,  0.1931],\n",
      "        [-1.1060,  0.4704, -0.2433, -0.5874, -0.4257, -0.6259,  0.6032],\n",
      "        [-0.3435, -0.0980, -0.5696,  0.4407, -0.0433,  0.3585,  0.1362],\n",
      "        [-0.1456,  0.3126,  0.2726, -0.9562, -0.8213, -0.3716,  0.5941],\n",
      "        [-0.2149,  0.2231, -0.9932,  0.5629,  0.5268, -0.3696,  0.0874]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 5\n",
      "Weight:\n",
      "tensor([[ 0.1009, -0.3853,  0.0368, -0.4540, -0.4380, -0.0670, -0.4403],\n",
      "        [ 0.6768,  0.2805,  0.6309,  0.2574, -0.1615, -0.1747,  0.4323],\n",
      "        [-0.0931, -0.3302, -0.5611, -0.2625, -0.0595, -0.6052,  0.8249],\n",
      "        [ 1.0519,  0.1276, -0.5369, -0.2052, -0.2009, -0.1320,  1.0420],\n",
      "        [ 0.0492, -0.1396, -0.9988,  0.0414,  0.0459, -0.3264, -1.2869],\n",
      "        [ 0.4954,  0.2798, -0.2022,  0.3336,  0.8133, -0.3201,  0.6685],\n",
      "        [ 0.8906,  0.0892, -0.0038, -0.6008, -0.2570, -0.0816, -0.0066]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 6\n",
      "Weight:\n",
      "tensor([[-1.1746, -0.6904, -0.3287, -0.0416, -0.1733, -0.0232, -0.3226],\n",
      "        [-0.2905, -0.2195,  0.5026,  0.7051, -0.2898,  0.3042, -0.0983],\n",
      "        [-0.1882, -0.3245,  0.6044, -0.5695,  0.1159,  1.5630,  0.4904],\n",
      "        [-0.0054,  0.3512,  0.1458, -0.3826,  0.2590,  0.3912,  0.4872],\n",
      "        [ 0.1353,  0.1531, -0.0453,  0.4262,  0.2620,  0.5757, -0.1258],\n",
      "        [-0.0917,  0.3530,  0.2112, -0.4207, -0.6895,  0.7982,  0.0857],\n",
      "        [-0.1348,  0.2213,  1.0095,  0.2629, -0.3495, -1.2156,  0.3347]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 7\n",
      "Weight:\n",
      "tensor([[ 0.3664,  0.2047,  0.2935,  0.3322, -0.1254,  0.5008, -0.1656],\n",
      "        [ 0.2601, -0.0764,  0.2412, -0.1289,  0.9870,  0.4339,  0.3704],\n",
      "        [-0.6455, -1.0067,  0.5543,  1.5753, -0.3543,  0.0957,  0.8867],\n",
      "        [-0.4591,  0.1147,  0.4374, -0.2511, -0.4890, -0.3047, -0.4266],\n",
      "        [ 0.1397, -0.1651,  0.8518, -0.0484, -0.1188, -0.4442,  0.4956],\n",
      "        [ 1.2087,  0.1735, -0.2892,  0.6131,  0.2068,  0.6849, -0.1398],\n",
      "        [ 0.9705, -0.2561, -0.2429, -0.7749,  0.9491, -0.0212, -0.1737]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 8\n",
      "Weight:\n",
      "tensor([[ 0.6289, -0.0879, -0.8610,  0.3710,  0.1778,  0.9245,  0.1028],\n",
      "        [-0.3965,  0.0653,  1.0435, -0.3616, -0.2773, -0.1538, -0.2562],\n",
      "        [-0.2462, -0.6189,  0.1822, -0.0796,  0.4932,  0.4096,  0.1522],\n",
      "        [-0.2252, -0.3882,  0.5134,  0.2689, -0.3421,  0.4927,  0.0038],\n",
      "        [ 0.0567,  0.2283,  0.3299, -1.0837, -0.3701,  0.2546, -0.0060],\n",
      "        [ 0.0903, -0.1677,  0.6272,  0.1524,  0.1383,  0.2606, -0.1180],\n",
      "        [ 0.0291,  0.2490,  0.5029,  0.3559, -0.2441,  0.1945,  0.1847]])Weight gradient:\n",
      "None\n",
      "\n",
      "-----\n",
      "Layer 9\n",
      "Weight:\n",
      "tensor([[-0.0688,  0.4294, -0.7579,  0.3925,  0.4945, -0.2480, -0.1614],\n",
      "        [-0.2724,  0.4229,  0.0573,  0.3386, -0.3870,  1.0552, -0.6156],\n",
      "        [-0.4026, -0.9007, -0.2695, -0.5177, -0.3699, -0.0616, -0.0512],\n",
      "        [ 0.3623,  0.0877,  0.2097, -0.3174, -0.9256,  0.7691, -1.1048],\n",
      "        [-0.0054,  0.3573, -0.2189, -0.2419,  0.2915,  0.2092, -0.4534],\n",
      "        [ 0.6693, -0.4130, -0.0347,  0.3008, -0.7064,  0.1705, -0.6194],\n",
      "        [ 0.0239, -0.5009, -0.0022,  0.4796, -0.0286, -0.2365,  0.8795]])Weight gradient:\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relu_model = RandomReluModel(10)\n",
    "tanh_model = RandomTanhModel(10)\n",
    "relu_model.print_weights_grads()\n",
    "tanh_model.print_weights_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3972, -2.1135,  5.7464,  4.4670,  5.0665, -0.6776, -0.8563],\n",
      "        [-0.1815, -0.2374,  0.0330,  0.0564,  0.0431, -0.1805, -0.2352],\n",
      "        [-0.6487, -1.5973,  0.4207,  2.5513,  1.0361, -0.6041, -0.9996],\n",
      "        [-1.9112, -0.5602,  3.6527,  0.3138,  1.0707, -0.9426, -0.5314],\n",
      "        [ 0.8331, -0.7917,  0.6940,  0.6268, -0.6596,  0.7400, -0.7115],\n",
      "        [ 2.5585,  1.9516,  6.5460,  3.8087,  4.9931,  0.5506,  0.9284],\n",
      "        [-1.8898, -0.6932,  3.5713,  0.4806,  1.3100, -0.9496, -0.6390],\n",
      "        [-2.2680, -3.9058,  5.1436, 15.2554,  8.8582, -0.7667,  0.6920]])\n",
      "ReLU model ouput:\n",
      " None\n",
      "tanh model ouput:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "data_in, data_out = next(iter(train_loader))\n",
    "relu_output = relu_model.forward(Variable(data_in))\n",
    "tanh_output = tanh_model.forward(Variable(data_in))\n",
    "print(data_in)\n",
    "print(\"ReLU model ouput:\\n\", relu_output)\n",
    "print(\"tanh model ouput:\\n\", tanh_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Exercice\n",
    "Vérifiez que le réseau retourne bel et bien des probabilités. Identifiez la ligne de code qui transforme des nombres arbitraires en probabilité. Indice: il y a une erreur volontaire dans le code que vous devez corriger.\n",
    "\n",
    "#### Analyse du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.NLLLoss()\n",
    "relu_loss = loss(relu_output, Variable(data_out))\n",
    "tanh_loss = loss(tanh_output, Variable(data_out))\n",
    "print(relu_loss, tanh_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_loss.backward()\n",
    "tanh_loss.backward()\n",
    "relu_model.print_weights_grads()\n",
    "tanh_model.print_weights_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique suivant représente la quantité de poids qui ont un gradient nul lors de la backprop en fonction du numéro de la couche. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(relu_model.nonzero_grad_stats)), [x[0] for x in relu_model.nonzero_grad_stats], label='ReLU')\n",
    "plt.plot(np.arange(len(tanh_model.nonzero_grad_stats)), [x[0] for x in tanh_model.nonzero_grad_stats], label='Tanh')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique suivant représente le gradient moyen (sans tenir compte des gradients nuls) en fonction du numéro de couche. La partie du bas est un zoom sur les premières couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(np.arange(len(relu_model.nonzero_grad_stats)), [x[1] / x[0] for x in relu_model.nonzero_grad_stats],label='ReLU')\n",
    "axs[0].plot(np.arange(len(tanh_model.nonzero_grad_stats)), [x[1] / x[0] for x in tanh_model.nonzero_grad_stats],label='Tanh')\n",
    "axs[0].legend()\n",
    "axs[1].plot(np.arange(4), [x[1] / x[0] for x in relu_model.nonzero_grad_stats[:4]])\n",
    "axs[1].plot(np.arange(4), [x[1] / x[0] for x in tanh_model.nonzero_grad_stats[:4]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante compte le nombre de fois que chaque poids a un gradient non-nul en passant plusieurs points dans le réseaux et en incrémentant le compteur à chaque fois que cela arrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = 1\n",
    "heatmap = np.zeros((7,7))\n",
    "n_batch = 0\n",
    "for data in train_loader:\n",
    "    n_batch += 1\n",
    "    data_in = Variable(data[0])\n",
    "    relu_model.forward(data_in)\n",
    "    nonzero_grad_indices = torch.nonzero(relu_model.layers[layer_index].weight.grad.data)\n",
    "    for (i, j) in nonzero_grad_indices:\n",
    "        heatmap[i,j] += 1\n",
    "print(n_batch)\n",
    "print(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "n_epoch = 1000\n",
    "relu_losses = []\n",
    "tanh_losses = []\n",
    "relu_optimizer = SGD(relu_model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "tanh_optimizer = SGD(tanh_model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"================\\nEpoch %d done.\" % epoch)\n",
    "    relu_epoch_losses = []\n",
    "    tanh_epoch_losses = []\n",
    "    for data_in, data_out in map(lambda data: (Variable(data[0]), Variable(data[1])),\n",
    "                                 train_loader):\n",
    "        relu_optimizer.zero_grad()\n",
    "        tanh_optimizer.zero_grad()\n",
    "        \n",
    "        relu_loss = loss(relu_model(data_in), data_out)\n",
    "        tanh_loss = loss(tanh_model(data_in), data_out)\n",
    "        relu_epoch_losses.append(float(relu_loss))\n",
    "        tanh_epoch_losses.append(float(tanh_loss))\n",
    "        \n",
    "        relu_loss.backward()\n",
    "        tanh_loss.backward()\n",
    "        relu_optimizer.step()\n",
    "        tanh_optimizer.step()\n",
    "    relu_losses.append(np.mean(np.asarray(relu_epoch_losses)))\n",
    "    tanh_losses.append(np.mean(np.asarray(tanh_epoch_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(relu_losses)), np.asarray(relu_losses),label='ReLU')\n",
    "plt.plot(np.arange(len(tanh_losses)), np.asarray(tanh_losses),label='Tanh')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Observez la distribution du gradient lors de la backprop. Quelles différences y a-t-il entre la backprop à travers ReLU et à travers tanh?\n",
    "- Est-ce que, pour deux entrées différentes, les mêmes poids ont un gradient élevé?\n",
    "- Changez le nombre de couches du réseau. Qu'observez-vous?\n",
    "- Changez la moyenne de la gaussienne des poids lors de l'initilisation. Qu'observez-vous?\n",
    "- Identifiez un problème avec la tanh. Identifiez un problème avec la ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
